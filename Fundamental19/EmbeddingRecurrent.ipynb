{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 레이어의 이해(2) Embedding, Recurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 레이어의 개념을 이해한다.\n",
    "2. 딥러닝 모델 속 각 레이어(Embedding, RNN, LSTM)의 동작 방식을 이해한다.\n",
    "3. 데이터의 특성을 고려한 레이어를 설계하고, 이를 Tensorflow로 정의하는 법을 배운다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 분포 가설과 분산 표현\n",
    "2. 단어를 부탁해! Embedding 레이어\n",
    "3. 순차적인 데이터! Recurrent 레이어 (1) RNN\n",
    "4. 순차적인 데이터! Recurrent 레이어 (2) LSTM\n",
    "5. 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분포 가설과 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 희소 표현(Sparse Representation) : 벡터의 특정 차원에 단어 혹은 의미를 직접 매핑하는 방식\n",
    "  - 사과: [ 0, 0 ] , 바나나: [ 1, 1 ] , 배: [ 0, 1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단어의 분산 표현(Distributed Representation)\n",
    "  - 모든 단어들을 고정 차원의 벡터로 \n",
    "  - 분포 가설(distribution hypothesis) : 유사한 맥락에서 나타나는 단어는 그 의미도 비슷하다\n",
    "  - 비슷한 맥락의 단어들의 벡터들의 사이거리는 가깝게, 다른 맥락의 단어는 거리가 멀게하는 것\n",
    "  - 희소 표현과 다르게 단어간의 유사성을 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 n개를 k차원으로 표현, n x k 형태의 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weight : 단어의 개수, 단어를 더 깊이 표현(Embedding Size)\n",
    "* 입력으로 들어온 단어를 분산 표현으로 연결해주는 역할 = Weight에서 특정 행을 읽어오는 것\n",
    "* Lookup Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 12:01:04.142449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:04.142469: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "(10, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 12:01:07.976545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 12:01:07.976805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.976887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.976929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.976968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.977004: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.977092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.977127: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.977164: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-08-05 12:01:07.977171: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-05 12:01:07.978224: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vocab = {      # 사용할 단어 사전 정의\n",
    "    \"i\": 0,\n",
    "    \"need\": 1,\n",
    "    \"some\": 2,\n",
    "    \"more\": 3,\n",
    "    \"coffee\": 4,\n",
    "    \"cake\": 5,\n",
    "    \"cat\": 6,\n",
    "    \"dog\": 7\n",
    "}\n",
    "\n",
    "sentence = \"i i i i need some more coffee coffee coffee\"\n",
    "# 위 sentence\n",
    "# 위 sentence를 split 한뒤 단어에 해당하는 것을 vocab에서 찾아서 해당 index로 반환\n",
    "_input = [vocab[w] for w in sentence.split()]  # [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
    "\n",
    "vocab_size = len(vocab)   # 8\n",
    "\n",
    "one_hot = tf.one_hot(_input, vocab_size) \n",
    "print(one_hot.numpy())    # 원-핫 인코딩 벡터를 출력해 봅시다.\n",
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* one_hot encoding 이유 : 단어 단위로 나눠서 벡터 [0,1...]\n",
    "* one_hot endcoding만 보면 단순 희소 표현이랑 같다.\n",
    "* Word Embedding은 이런 one_hot encoding으로만 하면 너무 커짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_size = 2   # 보기 좋게 2차원으로 분산 표현하도록 하죠!\n",
    "linear = tf.keras.layers.Dense(units=distribution_size, use_bias=False)\n",
    "one_hot_linear = linear(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear weight\n",
      "[<tf.Variable 'dense/kernel:0' shape=(8, 2) dtype=float32, numpy=\n",
      "array([[ 0.19873261,  0.27038038],\n",
      "       [-0.32390717, -0.06339896],\n",
      "       [ 0.723773  , -0.4230373 ],\n",
      "       [-0.2552861 ,  0.33351672],\n",
      "       [-0.19027472,  0.59898186],\n",
      "       [-0.01339561, -0.4244931 ],\n",
      "       [-0.14496893, -0.6882508 ],\n",
      "       [-0.2884146 , -0.04055977]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(\"linear weight\")\n",
    "print(linear.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot_linear\n",
      "tf.Tensor(\n",
      "[[ 0.19873261  0.27038038]\n",
      " [ 0.19873261  0.27038038]\n",
      " [ 0.19873261  0.27038038]\n",
      " [ 0.19873261  0.27038038]\n",
      " [-0.32390717 -0.06339896]\n",
      " [ 0.723773   -0.4230373 ]\n",
      " [-0.2552861   0.33351672]\n",
      " [-0.19027472  0.59898186]\n",
      " [-0.19027472  0.59898186]\n",
      " [-0.19027472  0.59898186]], shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"one_hot_linear\")\n",
    "print(one_hot_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dense Weight에서 input(one_hot Encodding)의 1에 해당하는 부분의 2개의 값을 가져옴  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Weight numpy\n",
      "[[ 0.19873261  0.27038038]\n",
      " [-0.32390717 -0.06339896]\n",
      " [ 0.723773   -0.4230373 ]\n",
      " [-0.2552861   0.33351672]\n",
      " [-0.19027472  0.59898186]\n",
      " [-0.01339561 -0.4244931 ]\n",
      " [-0.14496893 -0.6882508 ]\n",
      " [-0.2884146  -0.04055977]]\n",
      "\n",
      "One-Hot Linear Result\n",
      "[[ 0.19873261  0.27038038]\n",
      " [ 0.19873261  0.27038038]\n",
      " [ 0.19873261  0.27038038]\n",
      " [ 0.19873261  0.27038038]\n",
      " [-0.32390717 -0.06339896]\n",
      " [ 0.723773   -0.4230373 ]\n",
      " [-0.2552861   0.33351672]\n",
      " [-0.19027472  0.59898186]\n",
      " [-0.19027472  0.59898186]\n",
      " [-0.19027472  0.59898186]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Weight numpy\")\n",
    "print(linear.weights[0].numpy())\n",
    "\n",
    "print(\"\\nOne-Hot Linear Result\")\n",
    "print(one_hot_linear.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_words : tf.Tensor([[ 3 57 35]], shape=(1, 3), dtype=int32)\n",
      "Embedding을 진행할 문장: (1, 3)\n",
      "Embedding된 문장: (1, 3, 100)\n",
      "Embedding Layer의 Weight 형태: (64, 100)\n"
     ]
    }
   ],
   "source": [
    "some_words = tf.constant([[3, 57, 35]])\n",
    "# 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.\n",
    "print('some_words :', some_words)\n",
    "\n",
    "print(\"Embedding을 진행할 문장:\", some_words.shape)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=64, output_dim=100)\n",
    "# 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,\n",
    "# 각 단어는 100차원으로 분산 표현 할 것입니다.\n",
    "\n",
    "print(\"Embedding된 문장:\", embedding_layer(some_words).shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Layer는 결국 단어를 대응만 시킬 뿐이니 미분이 불가능합니다.  \n",
    "어떤 연산결과를  Embedding Layer에 연결시키는 것은 불가능합니다.  \n",
    "즉 입력에 바로 Embedding Layer를 연결되게 사용(이때 입력은 one_hot encoding이 이상적)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공지능이 예측을 하기 위해서는 요소간의 연관성이 있어야한다.  \n",
    "고로 딥러닝에서의 시퀀스 데이터는 순차적인 특성을 가진다. \n",
    "문장, 영상, 음성은 순차적인 데이터   \n",
    "이런 순차적인 데이터를 처리하기 위해 고안된 것이 바로 Recurrent Neural Network 또는 Recurrent Layer(RNN) 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이전 정보를 반영하는 2가지 방법\n",
    "  1. (input + prev_hidden) -> hidden -> output\n",
    "     - Previous hidden : hidden 에서 가져온다.\n",
    "     - 전부 다 기억할 수 있음\n",
    "  2. (input _ prev_input ) -> hidden -> output\n",
    "     - Previous input  : input 에서 가져온다.\n",
    "     - 바로 직전만을 기억함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hidden 을 만드는 것이 tanh 라고 합니다\n",
    "  - sigmoid 보다 tanh 가 기울기의 역전파를 잘 만들어냄\n",
    "  - sigmoid 미분의 최댓값은 0.25정도, tanh 미분의 최댓값은 1이므로 tanh 가 gradient vanishing에 더 강하다.\n",
    "* 자동 완성사례에서는 input이 그 전의 output을 사용합니다.(2번째 뉴런의 input이 1번째의 output(1번째 글자))  \n",
    "    (단 여기서 예시를 1번째 글자를 넣으면 나머지 글자를 나오게 하는 모델입니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RNN의 입력으로 들어가는 모든 단어만큼 Weight를 만드는 것이 아님.\n",
    "* (입력차원, 출력차원의 크기의) 하나의 Weight를 순차적으로 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'GradientLoss.png' width = 50%, height = 50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기 소실(Vanishing Gradient) : What의 정보(앞부분의 정보)가 가면 갈수록 희석되는 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Layer 와 RNN Layer의 구체적인 형태를 보여주는 코드  \n",
    "[TensorFlow RNN](https://www.tensorflow.org/guide/keras/rnn?hl=ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN에 입력할 문장: What time is it ?\n",
      "Embedding을 위해 단어 매핑: [[2 3 0 1 4]]\n",
      "입력 문장 데이터 형태: (1, 5)\n",
      "\n",
      "Embedding 결과: (1, 5, 100)\n",
      "Embedding Layer의 Weight 형태: (5, 100)\n",
      "\n",
      "RNN 결과 (모든 Step Output): (1, 5, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n",
      "\n",
      "RNN 결과 (최종 Step Output): (1, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "print(\"RNN에 입력할 문장:\", sentence)\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "print(\"Embedding을 위해 단어 매핑:\", sentence_tensor.numpy())\n",
    "print(\"입력 문장 데이터 형태:\", sentence_tensor.shape)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"\\nEmbedding 결과:\", emb_out.shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
    "\n",
    "rnn_seq_layer = \\\n",
    "tf.keras.layers.SimpleRNN(units=64, return_sequences=True, use_bias=False)\n",
    "rnn_seq_out = rnn_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (모든 Step Output):\", rnn_seq_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_seq_layer.weights[0].shape)\n",
    "\n",
    "rnn_fin_layer = tf.keras.layers.SimpleRNN(units=64, use_bias=False)\n",
    "rnn_fin_out = rnn_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (최종 Step Output):\", rnn_fin_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문장의 긍정/부정을 구분하는 것은 문장을 모두 읽은 뒤, 최종 Step의 Output만 확인해도 판단 가능\n",
    "* 문장을 생성하는 경우는 모든 step에 대한 Output이 필요\n",
    "* 위는 tf.keras.layers.SimpleRNN 레이어의 return_sequences 인자 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM 결과 (모든 Step Output): (1, 5, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n",
      "\n",
      "LSTM 결과 (최종 Step Output): (1, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n"
     ]
    }
   ],
   "source": [
    "lstm_seq_layer = tf.keras.layers.LSTM(units=64, return_sequences=True, use_bias=False)\n",
    "lstm_seq_out = lstm_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (모든 Step Output):\", lstm_seq_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_seq_layer.weights[0].shape)\n",
    "\n",
    "lstm_fin_layer = tf.keras.layers.LSTM(units=64, use_bias=False)\n",
    "lstm_fin_out = lstm_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (최종 Step Output):\", lstm_fin_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 의 Weight 의 크기가 RNN 의 4배 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RNN 은 장기 의존성(Long-Term Dependency) 을 잘 다루지 못한다.  \n",
    "* LSTM 은 Long Short-Term Memory의 약어로 기울기 소실 문제를 해결하기 위해 고안된 RNN Layer  \n",
    "* Deep Learning Network 는 각 가중치의 미분을 구해 업데이트하는 backpropagation을 통해 학습함.\n",
    "* RNN은 입력되는 문장의 길이가 길수록 초기에 입력된 단어들의 미분 값이 매우 작아지거나 커지는 현상\n",
    "* 너무 작아지는 것 : Vanishing Gradient : 학습이 제대로 안됨 - RNN 구조 변경(tanh 사용 등)을 통해 방지\n",
    "* 너무 커지는 것 : Exploding Gradient   : 학습이 불안정함 - Gradient clipping을 통해 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cell state = c\n",
    "* hidden state = h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'LSTM1.png' width = 50%, height = 50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weight에서 나오는 Gate\n",
    "1. Input gate : 셀에 적을 것인지? - i[0,1] - sigmoid\n",
    "2. Forget gate : 셀을 지울 것인지? - f[0,1] - sigmoid\n",
    "3. Ouput gate : 셀을 얼마나 드러낼 것인지? - o[0,1] - sigmoid\n",
    "4. Gate gate(?): 셀에 얼마나 적을 것인지 - g[-1,1] - tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작동 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'LSTM2.png' width = 50%, height = 50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 RNN의 Weight 하나를 계속 바꾸는 시스템(exploding, vanishing gradient 유발)과 다르게  \n",
    "LSTM은 f가 task마다 바뀌니까 더 좋음.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gated Recurrent Unit\n",
    "* cell state 와 hidden state 를 합침.\n",
    "* forget gate 와 input gate 를 통합.\n",
    "* 학습하는 가중치의 양이 줄어든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 양방향(Bidirectional) RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 한쪽 방향으로만 학습할 경우 target의 예측하기 힘든 경우\n",
    "* tf.keras.layers.Bidirectional() 로 Layer를 감싸주면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장 데이터 형태: (1, 5, 100)\n",
      "Bidirectional RNN 결과 (최종 Step Output): (1, 5, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"입력 문장 데이터 형태:\", emb_out.shape)\n",
    "\n",
    "bi_rnn = \\\n",
    "tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True)\n",
    ")\n",
    "bi_out = bi_rnn(emb_out)\n",
    "\n",
    "print(\"Bidirectional RNN 결과 (최종 Step Output):\", bi_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 RNN의 크기가 2배가 되었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
